{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_load_and_filter_data(start_date, end_date, path='data/'):\n",
    "    \"\"\"\n",
    "    Intelligent data loading and processing for specified date range with automatic missing file handling\n",
    "    \n",
    "    This function combines file discovery, robust loading, and data processing into a single streamlined\n",
    "    pipeline. It automatically generates date ranges, checks for file existence, handles datetime conversion,\n",
    "    merges environmental data, and calculates refractive index parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    start_date : str\n",
    "        Start date in YYYYMMDD format (e.g., '20250101')\n",
    "    end_date : str\n",
    "        End date in YYYYMMDD format (e.g., '20250310')\n",
    "    path : str, optional\n",
    "        Base directory path for data files (default: 'data/')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Processed dataset with the following columns:\n",
    "        - laser_offset: Filtered laser offset values (-200 to 0)\n",
    "        - temperature: Environmental temperature in °C\n",
    "        - humidity: Relative humidity in %\n",
    "        - pressure: Atmospheric pressure in hPa\n",
    "        - counts_ratio: Calculated optical counts ratio\n",
    "        - n_1762: Refractive index at 1762 nm wavelength\n",
    "        Index: Timestamp (datetime index)\n",
    "        \n",
    "    Raises:\n",
    "    -------\n",
    "    ValueError\n",
    "        If no complete date data is found in the specified range\n",
    "    FileNotFoundError\n",
    "        If required data files are missing for valid dates\n",
    "        \n",
    "    Example:\n",
    "    --------\n",
    "    >>> df = smart_load_and_filter_data('20250101', '20250310', path='experiment_data/')\n",
    "    >>> print(f\"Loaded {len(df)} records\")\n",
    "    \"\"\"\n",
    "    \n",
    "    def generate_date_list(start_date, end_date):\n",
    "        \"\"\"Generate list of dates between start and end dates in YYYYMMDD format\"\"\"\n",
    "        start = datetime.strptime(start_date, \"%Y%m%d\")\n",
    "        end = datetime.strptime(end_date, \"%Y%m%d\")\n",
    "        date_list = []\n",
    "        \n",
    "        current = start\n",
    "        while current <= end:\n",
    "            date_list.append(current.strftime(\"%Y%m%d\"))\n",
    "            current += timedelta(days=1)\n",
    "        \n",
    "        return date_list\n",
    "    \n",
    "    # Generate date range and build file path lists\n",
    "    date_list = generate_date_list(start_date, end_date)\n",
    "    offset_files, humidity_files, pressure_files, temp_files = [], [], [], []\n",
    "    \n",
    "    # Check file existence and build complete file lists\n",
    "    for date in date_list:\n",
    "        offset_path = os.path.join(path, f'offset_data_{date}.csv')\n",
    "        humidity_path = os.path.join(path, f'humidity_data_{date}.csv')\n",
    "        pressure_path = os.path.join(path, f'pressure_data_{date}.csv')\n",
    "        temp_path = os.path.join(path, f'temperature_data_{date}.csv')\n",
    "        \n",
    "        # Only process dates with complete data files\n",
    "        if all(os.path.exists(p) for p in [offset_path, humidity_path, pressure_path, temp_path]):\n",
    "            offset_files.append(offset_path)\n",
    "            humidity_files.append(humidity_path)\n",
    "            pressure_files.append(pressure_path)\n",
    "            temp_files.append(temp_path)\n",
    "        else:\n",
    "            print(f\"Skipping {date}: Incomplete files\")\n",
    "    \n",
    "    # Validate that we have at least one complete date\n",
    "    if not offset_files:\n",
    "        raise ValueError(f\"No complete date data found in range {start_date} to {end_date}\")\n",
    "    \n",
    "    print(f\"Processing {len(offset_files)} complete days of data\")\n",
    "    \n",
    "    # Initialize lists for data storage\n",
    "    offset_dfs, humidity_dfs, pressure_dfs, temp_dfs = [], [], [], []\n",
    "    \n",
    "    # Load and validate all data files\n",
    "    for offset_file, humidity_file, pressure_file, temp_file in zip(\n",
    "        offset_files, humidity_files, pressure_files, temp_files\n",
    "    ):\n",
    "        try:\n",
    "            # Load CSV files\n",
    "            offset_df = pd.read_csv(offset_file)\n",
    "            humidity_df = pd.read_csv(humidity_file)\n",
    "            pressure_df = pd.read_csv(pressure_file)\n",
    "            temp_df = pd.read_csv(temp_file)\n",
    "            \n",
    "            # Ensure time column is datetime type\n",
    "            for df in [offset_df, humidity_df, pressure_df, temp_df]:\n",
    "                if 'time' in df.columns and not pd.api.types.is_datetime64_any_dtype(df['time']):\n",
    "                    df['time'] = pd.to_datetime(df['time'])\n",
    "            \n",
    "            # Store validated dataframes\n",
    "            offset_dfs.append(offset_df)\n",
    "            humidity_dfs.append(humidity_df)\n",
    "            pressure_dfs.append(pressure_df)\n",
    "            temp_dfs.append(temp_df)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {offset_file}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Check if we have valid data after loading\n",
    "    if not offset_dfs:\n",
    "        raise ValueError(\"All data files failed to load or were invalid\")\n",
    "    \n",
    "    # Concatenate all data across dates\n",
    "    offset_df = pd.concat(offset_dfs, ignore_index=True)\n",
    "    humidity_df = pd.concat(humidity_dfs, ignore_index=True)\n",
    "    pressure_df = pd.concat(pressure_dfs, ignore_index=True)\n",
    "    temp_df = pd.concat(temp_dfs, ignore_index=True)\n",
    "    \n",
    "    # Filter valid laser offset range (-200 to 0)\n",
    "    valid_offset = offset_df[(offset_df['offset'] >= -200) & (offset_df['offset'] <= 0)].copy()\n",
    "    \n",
    "    # Standardize column names\n",
    "    humidity_df = humidity_df.rename(columns={'humidity_wm_bme280': 'humidity'})\n",
    "    pressure_df = pressure_df.rename(columns={'pressure_wm_bme280': 'pressure'})\n",
    "    temp_df = temp_df.rename(columns={'temperature_wm_bme280': 'temperature'})\n",
    "    \n",
    "    # Final datetime type verification\n",
    "    for df in [valid_offset, humidity_df, temp_df, pressure_df]:\n",
    "        if not pd.api.types.is_datetime64_any_dtype(df['time']):\n",
    "            df['time'] = pd.to_datetime(df['time'])\n",
    "    \n",
    "    # Sort data for temporal merging\n",
    "    sorted_offset = valid_offset.sort_values('time')\n",
    "    sorted_humidity = humidity_df[['time', 'humidity']].sort_values('time')\n",
    "    sorted_temp = temp_df[['time', 'temperature']].sort_values('time')\n",
    "    sorted_pressure = pressure_df[['time', 'pressure']].sort_values('time')\n",
    "    \n",
    "    # Merge environmental data using nearest timestamp matching\n",
    "    env_df = pd.merge_asof(sorted_offset, sorted_humidity, on='time', direction='nearest')\n",
    "    env_df = pd.merge_asof(env_df.sort_values('time'), sorted_temp, on='time', direction='nearest')\n",
    "    env_df = pd.merge_asof(env_df.sort_values('time'), sorted_pressure, on='time', direction='nearest')\n",
    "    \n",
    "    # Define refractive index calculation functions\n",
    "    def offset2countsratio(offset, temperature, pressure, humidity):\n",
    "        \"\"\"\n",
    "        Convert laser offset to optical counts ratio using Ciddor's refractive index equation\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        offset : float\n",
    "            Laser frequency offset in Hz\n",
    "        temperature : float\n",
    "            Temperature in °C\n",
    "        pressure : float\n",
    "            Pressure in hPa\n",
    "        humidity : float\n",
    "            Relative humidity in %\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        float\n",
    "            Optical counts ratio\n",
    "        \"\"\"\n",
    "        f_1762 = 170.12643244933331e12  # 1762 nm laser frequency\n",
    "        f_rb = 384.2281145e12  # Rubidium reference frequency\n",
    "        n_rb = ciddor(wave=299792458/f_rb*1e9, t=temperature, p=pressure, rh=humidity)\n",
    "        n_1762 = ciddor(wave=1762, t=temperature, p=pressure, rh=humidity)\n",
    "        return n_rb/n_1762 * f_rb/((offset*1e-6 + 170.12643244933331)*1e12)\n",
    "\n",
    "    def offset2n1762(ratio, temperature, pressure, humidity):\n",
    "        \"\"\"\n",
    "        Convert counts ratio to refractive index at 1762 nm wavelength\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        ratio : float\n",
    "            Optical counts ratio from offset2countsratio\n",
    "        temperature : float\n",
    "            Temperature in °C\n",
    "        pressure : float\n",
    "            Pressure in hPa\n",
    "        humidity : float\n",
    "            Relative humidity in %\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        float\n",
    "            Refractive index at 1762 nm\n",
    "        \"\"\"\n",
    "        f_1762 = 170.126432e12  # 1762 nm laser frequency\n",
    "        f_rb = 384.2281145e12  # Rubidium reference frequency\n",
    "        n_rb = ciddor(wave=299792458/f_rb*1e9, t=temperature, p=pressure*100, rh=humidity)\n",
    "        return n_rb * f_rb / f_1762 / ratio\n",
    "    \n",
    "    # Calculate derived optical parameters\n",
    "    env_df['counts_ratio'] = env_df.apply(\n",
    "        lambda row: offset2countsratio(\n",
    "            offset=row['offset'],\n",
    "            temperature=row['temperature'],\n",
    "            pressure=row['pressure'],\n",
    "            humidity=row['humidity']\n",
    "        ), axis=1\n",
    "    )\n",
    "\n",
    "    env_df['n_1762'] = env_df.apply(\n",
    "        lambda row: offset2n1762(\n",
    "            ratio=row['counts_ratio'],\n",
    "            temperature=row['temperature'],\n",
    "            pressure=row['pressure'],\n",
    "            humidity=row['humidity']\n",
    "        ), axis=1\n",
    "    )\n",
    "\n",
    "    # Final dataframe preparation\n",
    "    final_df = env_df.set_index('time')\n",
    "    final_df = final_df.rename(columns={'offset': 'laser_offset'})\n",
    "    \n",
    "    print(f\"Successfully processed {len(final_df)} data points\")\n",
    "    print(f\"Date range: {final_df.index.min()} to {final_df.index.max()}\")\n",
    "    \n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
